{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPLvB+3mhZl0HrIRg8wfOVo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeong2624/Deep-Learning-for-the-Life-Sciences-coding-transcription/blob/main/%08Chapter3_Machine_Learning_with_DeepChem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Machine Learnning with DeepChem**\n",
        "\n",
        "해당 Chapter에서는 텐서플로 기반 머신러닝 라이브러리인 DeepChem으로 딥러닝을 생명과학 분야에 사용하는 방법을 소개.\n",
        "\n",
        "DeepChem 라이브러리에는 생명과학에 특화된 모델, 알고리즘, 데이터셋이 포함되어 있다.\n",
        "\n",
        "해당 라이브러리의 장점은 텐서플로 기반으로 하기 때문에 기존 머신러닝 생태계와 잘 융합된다는 점이다. 즉, DeepChem으로 작성한 코드도 텐서플로에서 작동할 수 있음!\n",
        "\n",
        "\n",
        "##### <font color=red>📌 **케라스, 텐서플로, Pytorch 라이브러리를 사용하지 않는 이유?**</font>\n",
        "- 라이브러리 개발자들은 핵심 사용자들이 원하는 기능을 제공하는 데 초점을 맞춤.\n",
        "- 예를 들어 케라스 (Keras) 라이브러리는 이미지 처리, 텍스트 처리, 음성 분석에 대해 광범위한 지원을 제공하지만, 분자 데이터의 처리, 유전학 데이터 또는 현미경 이미지에 대한 지원은 미비함."
      ],
      "metadata": {
        "id": "UVXOj9i39lHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install --pre deepchem\n",
        "!pip install numpy torch_geometric pytorch_lightning dm-haiku"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v5k61ZH8YmD",
        "outputId": "c7176675-8b54-43c8-f93c-e1538474758a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.10/dist-packages (2.7.2.dev20231105033457)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.12)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.11.3)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from deepchem) (2023.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2023.3.post1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.10/dist-packages (0.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.9.0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.4.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.0.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.9.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (3.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch_lightning) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch_lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. DeepChem의 기본 데이터셋**"
      ],
      "metadata": {
        "id": "ThNWbBg3_STh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import deepchem as dc\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wKKSO1z2_bOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848901fd-1ec7-4cbc-909c-d4f7f1e3f7ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with transformers dependency. No module named 'transformers'\n",
            "WARNING:deepchem.models:cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터셋은 데이터 각각에 대한 정보를 포함하는 입력 벡터 x와 출력 벡터 y로 구성되어 있고 추가적인 기타 정보 등도 포함하고 있음.\n",
        "\n",
        "* DeepChem은 데이터셋을 저장하기 위해 다양한 하위 클래스들을 사용하는데, NumpyDataset 클래스는 넘파이 배열로 편리하게 변환될 수 있어서 가장 많이 사용된다."
      ],
      "metadata": {
        "id": "utscn_TYAj-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 재현성을 위해 랜덤 시드 배정\n",
        "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html\n",
        "np.random.seed(20231106)\n",
        "\n",
        "# 간단한 넘파이 배열 만들기\n",
        "x = np.random.random((4, 5))\n",
        "y = np.random.random((4, 1))"
      ],
      "metadata": {
        "id": "3gTCML2X_lvd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 벡터 x 출력\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCvjmyM4BTMS",
        "outputId": "23549346-e567-4cb2-e21a-850b537ab95b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.73654008e-01, 1.19435956e-04, 4.40377417e-01, 2.08107329e-01,\n",
              "        4.57378254e-01],\n",
              "       [2.17120676e-01, 5.92927536e-02, 5.47143218e-01, 8.38110010e-01,\n",
              "        2.47595065e-02],\n",
              "       [8.46797765e-01, 4.20485983e-01, 3.64240020e-01, 8.14602497e-01,\n",
              "        7.76671479e-01],\n",
              "       [7.58009684e-02, 7.50731334e-01, 8.20427474e-01, 1.28505681e-01,\n",
              "        7.05276497e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 벡터 y 출력\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qai835x3BX4P",
        "outputId": "80b87a0f-970a-4a58-a96a-6a6f520966f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65499145],\n",
              "       [0.42909778],\n",
              "       [0.41402953],\n",
              "       [0.74893433]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 넘파이 배열을 NumpyDataset 객체로 저장\n",
        "dataset = dc.data.NumpyDataset(x, y)"
      ],
      "metadata": {
        "id": "NIDcGzgOBZ9z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NumpyDataset 객체 속에 저장된 원래의 넘파이 배열을 출력 (입력 벡터 x)\n",
        "print(dataset.X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BauStNnBfxC",
        "outputId": "b0a20086-417a-4d79-afd3-67a8a21726c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.73654008e-01 1.19435956e-04 4.40377417e-01 2.08107329e-01\n",
            "  4.57378254e-01]\n",
            " [2.17120676e-01 5.92927536e-02 5.47143218e-01 8.38110010e-01\n",
            "  2.47595065e-02]\n",
            " [8.46797765e-01 4.20485983e-01 3.64240020e-01 8.14602497e-01\n",
            "  7.76671479e-01]\n",
            " [7.58009684e-02 7.50731334e-01 8.20427474e-01 1.28505681e-01\n",
            "  7.05276497e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumpyDataset 객체 속에 저장된 원래의 넘파이 배열을 출력 (출력 벡터 y)\n",
        "print(dataset.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXRPMF35Bq-y",
        "outputId": "7ee06eb6-8a32-4d2e-fd59-844a452b96c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.65499145]\n",
            " [0.42909778]\n",
            " [0.41402953]\n",
            " [0.74893433]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력된 넘파이 배열이 원본과 동일한지 확인 (입력 벡터 x)\n",
        "# np.array_eqaul 관련 정보 -> https://numpy.org/doc/stable/reference/generated/numpy.equal.html\n",
        "# 비교 대상이 동일하면 True, 그렇지 않으면 False로 출력\n",
        "np.array_equal(x, dataset.X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Uc33ZmBwwi",
        "outputId": "23c2fcd8-93f2-40b4-b829-4fc2e44cc6de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력된 넘파이 배열이 원본과 동일한지 확인 (출력 벡터 x)\n",
        "# np.array_eqaul 관련 정보 -> https://numpy.org/doc/stable/reference/generated/numpy.equal.html\n",
        "# 비교 대상이 동일하면 True, 그렇지 않으면 False로 출력\n",
        "np.array_equal(x, dataset.X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpxMq_ucB_yK",
        "outputId": "85dcb7c2-6531-4504-ef0b-01378cb53e1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 독성 분자 예측 모델 만들기**"
      ],
      "metadata": {
        "id": "JNNGPFxSCUN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tox21 독성 데이터 불러오기\n",
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()"
      ],
      "metadata": {
        "id": "lpeeE8W4CEma"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tox21_tasks의 값 살펴보기\n",
        "tox21_tasks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajozj7aG0bXg",
        "outputId": "6f30413c-d60d-4655-aab7-3d4eb1c699ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NR-AR',\n",
              " 'NR-AR-LBD',\n",
              " 'NR-AhR',\n",
              " 'NR-Aromatase',\n",
              " 'NR-ER',\n",
              " 'NR-ER-LBD',\n",
              " 'NR-PPAR-gamma',\n",
              " 'SR-ARE',\n",
              " 'SR-ATAD5',\n",
              " 'SR-HSE',\n",
              " 'SR-MMP',\n",
              " 'SR-p53']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 데이터에 생물학적 표적 (Target)이 총 몇 개가 있는지 확인\n",
        "len(tox21_tasks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Op9s8qV0g2y",
        "outputId": "0d792867-27d7-4fd4-bb1a-805c85da8f1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tox21_datasets 객체 살펴보기\n",
        "# 해당 데이터에는 입력 및 출력 벡터의 shape, 생물학적 표적 (target) 정보, 각 표적에 대한 분자식 정보 등 들어 있다.\n",
        "tox21_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyZ9-IFv0lun",
        "outputId": "4f992efe-d687-4be2-9882-24c27de1223f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<DiskDataset X.shape: (6264, 1024), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>,\n",
              " <DiskDataset X.shape: (783, 1024), y.shape: (783, 12), w.shape: (783, 12), ids: ['N#C[C@@H]1CC(F)(F)CN1C(=O)CNC1CC2CCC(C1)N2c1ncccn1'\n",
              "  'CN(C)C(=O)NC1(c2ccccc2)CCN(CCC[C@@]2(c3ccc(Cl)c(Cl)c3)CCCN(C(=O)c3ccccc3)C2)CC1'\n",
              "  'CSc1nnc(C(C)(C)C)c(=O)n1N' ...\n",
              "  'O=C(O[C@H]1CN2CCC1CC2)N1CCc2ccccc2[C@@H]1c1ccccc1'\n",
              "  'C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@@H]4[C@H]3C(=C)C[C@@]21CC'\n",
              "  'NC(=O)C(c1ccccc1)(c1ccccc1)[C@@H]1CCN(CCc2ccc3c(c2)CCO3)C1'], task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>,\n",
              " <DiskDataset X.shape: (784, 1024), y.shape: (784, 12), w.shape: (784, 12), ids: ['CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O.CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O.c1ccc(CNCCNCc2ccccc2)cc1'\n",
              "  'CC(C)(c1ccc(Oc2ccc3c(c2)C(=O)OC3=O)cc1)c1ccc(Oc2ccc3c(c2)C(=O)OC3=O)cc1'\n",
              "  'Cc1cc(C(C)(C)C)c(O)c(C)c1Cn1c(=O)n(Cc2c(C)cc(C(C)(C)C)c(O)c2C)c(=O)n(Cc2c(C)cc(C(C)(C)C)c(O)c2C)c1=O'\n",
              "  ... 'CN[C@@H]1C[C@@H](c2ccc(Cl)c(Cl)c2)c2ccccc21'\n",
              "  'Cl/C=C\\\\C[N+]12CN3CN(CN(C3)C1)C2'\n",
              "  'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](O)[C@@H]3O)[C@@H](O)[C@H]2O)c1'], task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습을 위해 데이터셋을 분리\n",
        "# tox21_datasets 객체에는 train, validation, test dataset이 들어 있음.\n",
        "# 이것의 장점은 데이터셋을 반복해서 불러올 필요가 없음.\n",
        "train_dataset, valid_dataset, test_dataset = tox21_datasets"
      ],
      "metadata": {
        "id": "n0_oJQ7q0uuN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 입력 벡터 shape 확인 (train_dataset)\n",
        "train_dataset.X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFy1TPt1SXG",
        "outputId": "5a2d4ea0-e364-4696-da9d-21002b6709ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6264, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 입력 벡터 shape 확인 (valid_dataset)\n",
        "valid_dataset.X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grm-Y9Ek1mMm",
        "outputId": "bc38797b-c299-4a88-f4e2-9e841949001d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(783, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 입력 벡터 shape 확인 (test_dataset)\n",
        "test_dataset.X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASYBGiMd1prN",
        "outputId": "620100ba-09f8-482f-b4ab-d58352158150"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 출력 벡터 shape 확인 (train_dataset)\n",
        "np.shape(train_dataset.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUia8KeU1rg2",
        "outputId": "d7e29038-43c3-46c5-e2b5-f5b5ae8b5963"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6264, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 출력 벡터 shape 확인 (valid_dataset)\n",
        "np.shape(valid_dataset.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViAqGyLv11uT",
        "outputId": "53d22810-5207-49f4-9746-74db39bf84c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(783, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋의 출력 벡터 shape 확인 (test_dataset)\n",
        "np.shape(test_dataset.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6L1SezK14al",
        "outputId": "6285ad2b-38da-441f-efb7-5dfd006a3e73"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 데이터셋에 결측치가 존재하는지 확인\n",
        "# 총 11,521개의 element들이 결측치를 갖고 있음을 확인\n",
        "np.count_nonzero(train_dataset.w == 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLgp9ALO16UN",
        "outputId": "516771ef-be7d-4e3a-a621-02d8bf612ff5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11521"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformers 변수는 원본 데이터셋을 수정한 객체.\n",
        "# DeepChem은 원본 데이터를 변환하는 유용한 도구를 제공\n",
        "# 이 경우 어떤 도구가 사용됐는지 확인 -> BalancingTransformer : 가중치 행렬을 조정함으로서 불균형한 데이터셋을 보완하는 데 사용\n",
        "transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMuVC-Qa2LHG",
        "outputId": "29429465-ce14-4fd1-8f49-0b169298a3d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<deepchem.trans.transformers.BalancingTransformer at 0x7de05798cdc0>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중 분류 모델 생성\n",
        "# https://www.researchgate.net/figure/Example-code-for-benchmark-evaluation-with-DeepChem-multiple-methods-are-provided-for_fig1_314182452\n",
        "model = dc.models.MultitaskClassifier(\n",
        "    n_tasks = 12, # 12개의 데이터 포인트 (Label)\n",
        "    n_features = 1024, # 각 샘플의 feature 개수\n",
        "    layer_sizes = [1000], # 신경망의 hidden layer의 개수와 너비를 설정 (여기서는 너비가 1,000인 하나의 hidden layer 사용)\n",
        "    dropouts = [.25], # 몇 개의 신경망 hidden layer 층을 임의로 삭제할 것인가?\n",
        "    learning_rate = 0.001, # 한 번 학습할 때 얼마만큼 학습할 것인가?\n",
        "    batch_size = 50 # 모델 학습 중 parameter 업데이트 할 때 사용할 데이터의 개수\n",
        ")"
      ],
      "metadata": {
        "id": "adn0MxRv2xWS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "# nb_epoch = 10 : 한 번에 epoch의 경사 하강법 학습을 10번 수행한다는 의미\n",
        "# epoch : 데이터셋의 모든 샘플이 학습 알고리즘을 한 번 통과한다는 것을 의미\n",
        "model.fit(train_dataset, nb_epoch = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbnesfOX3WLz",
        "outputId": "3032a1b0-ee0b-4beb-8985-fad0ef343c37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35574881235758465"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC AUC 점수를 사용해 모델의 성능을 평가\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)"
      ],
      "metadata": {
        "id": "z-KjIFF-3q6W"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test 데이터셋에 대한 모델 성능 평가\n",
        "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "test_scores = model.evaluate(test_dataset, [metric], transformers)"
      ],
      "metadata": {
        "id": "aeWjzzUu4Imo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 ROC AUC 점수 출력\n",
        "print(train_scores)\n",
        "print(test_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chDtTedP4Vlq",
        "outputId": "b758518c-3d55-4adc-df7b-1ed320fb0436"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean-roc_auc_score': 0.9704947629837704}\n",
            "{'mean-roc_auc_score': 0.6721887166755774}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. MNIST 데이터셋으로 필기 인식 모델 만들기**\n",
        "\n",
        "* MNIST 필기 인식 데이터셋은 필기된 숫자를 올바르게 분류하는 머신러닝에 많이 사용됨.\n",
        "\n",
        "* MNIST 데이터셋에는 0에서 9까지의 숫자에 해당되는 28 × 28 픽셀의 흑백 이미지가 학습 데이터에 60,000개, 테스트 데이터에 10,000개씩 들어 있음."
      ],
      "metadata": {
        "id": "mfbah4xdAwED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 분석에 필요한 라이브러리 불러오기\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers"
      ],
      "metadata": {
        "id": "R9tjAyhrAyvu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터 불러오기\n",
        "# MNIST 객체에는 train, test dataset이 들어 있음.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 해당 데이터는 Categorical (범주형) 데이터로 만들어져 있기 때문에 모델이 학습할 수 있는 데이터 format으로 변환하기 위해 one-hot 인코딩 진행.\n",
        "# https://wikidocs.net/22647\n",
        "y_train = tf.one_hot(y_train, 10).numpy()\n",
        "y_test = tf.one_hot(y_test, 10).numpy()"
      ],
      "metadata": {
        "id": "lPHl9VZdB-tc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 데이터셋을 train, test 객체로 변환하기\n",
        "train_dataset = dc.data.NumpyDataset(x_train, y_train)\n",
        "test_dataset = dc.data.NumpyDataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "w15tm928CIaq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input size => 28 (가로) × 28 (세로) × 1 (흑백 이미지)\n",
        "features = tf.keras.Input(shape = (28, 28, 1))\n",
        "\n",
        "# 각 샘플에 2차원 합성곱 (2D convolution) 적용 / 활성 함수를 ReLU로 설정\n",
        "conv2d_1 = layers.Conv2D(filters = 32, kernel_size = 5, activation = tf.nn.relu)(features) # 차원 : 28 -> 32 , kernel : 5 × 5\n",
        "conv2d_2 = layers.Conv2D(filters = 64, kernel_size = 5, activation = tf.nn.relu)(conv2d_1) # 차원 : 32 -> 64, kernel : 5 × 5\n",
        "\n",
        "# Conv2d 레이어의 출력은 2차원 벡터이므로 1차원 벡터로 변환하기 위해 Flatten() 함수 사용\n",
        "flatten = layers.Flatten()(conv2d_2)\n",
        "dense1 = layers.Dense(units = 1024, activation = tf.nn.relu)(flatten)\n",
        "dense2 = layers.Dense(units = 10, activation = None)(dense1)\n",
        "\n",
        "# Output size : 1 × 1 (Label)\n",
        "# 차원 : 64 -> 1\n",
        "output = layers.Activation(tf.math.softmax)(dense2)\n",
        "\n",
        "# CNN 모델 생성\n",
        "keras_model = tf.keras.Model(inputs = features, outputs = [output, dense2])\n",
        "model = dc.models.KerasModel(\n",
        "    keras_model,\n",
        "    loss = dc.models.losses.SoftmaxCrossEntropy(), # 손실함수를 소프트맥스 교차 엔트로피로 설정\n",
        "    output_types = ['prediction', 'loss'], # 모델 성능 평가\n",
        "    model_dir = 'mnist') # model_dir : 모델의 매개변수를 저장하는 폴더를 지정"
      ],
      "metadata": {
        "id": "pb8inKOxCP_u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.fit(train_dataset, nb_epoch = 10)"
      ],
      "metadata": {
        "id": "H1_vyZOhoZN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Test 데이터셋에 대한 모델 성능 평가 (Accuracy)\n",
        "metric = dc.metrics.Metric(dc.metrics.accuracy_score)\n",
        "train_scores = model.evaluate(train_dataset, [metric])\n",
        "test_scores = model.evaluate(test_dataset, [metric])\n",
        "print(train_scores)\n",
        "print(test_scores)"
      ],
      "metadata": {
        "id": "i7G0X3Mpoa-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}